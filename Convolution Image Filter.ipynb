{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution As an Image Filter\n",
    "Justin Reising\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "from scipy.signal import convolve2d, convolve, fftconvolve\n",
    "from scipy.fftpack import fft2, ifft2, dctn, idctn\n",
    "from skimage import color\n",
    "np.set_printoptions( precision = 5, suppress = True, linewidth = 100 )\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.imread('etsuentrance.jpg')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the image is a tensor, we flatten it into a matrix by converting to grayscale. The convolution filters operate in the same manner regardless of the dimensions. However, flattening to a matrix simplifies calculations and improves calculation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = color.rgb2gray(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (8,4) )  #15.5,6))\n",
    "plt.gray() # plot image in grayscale\n",
    "plt.imshow(x);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution filters are defined by referencing the website: $$http://setosa.io/ev/image-kernels$$. We then verify that the results match the examples given in the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = {     'sharpen': np.array([[ 0, -1,  0],\n",
    "                               [-1,  5, -1],\n",
    "                               [ 0, -1,  0]]), \n",
    "       'left_sobel': np.array([[1, 0, -1],\n",
    "                               [2, 0, -2],\n",
    "                               [1, 0, -1]]),\n",
    "      'bottom_sobel':np.array([[-1, -2, -1],\n",
    "                               [ 0,  0,  0],\n",
    "                               [ 1,  2,  1]]),\n",
    "       'right_sobel':np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]]), \n",
    "      'EdgeDetector':np.array([[-1, -1, -1],\n",
    "                               [-1,  8, -1],\n",
    "                               [-1, -1, -1]]),\n",
    "         'Laplacian':np.array([[ 0, -1,  0],\n",
    "                               [-1,  4, -1],\n",
    "                               [ 0, -1,  0]]),\n",
    "       'top_sobel':np.array([[1,2,1],\n",
    "                           [0,0,0],\n",
    "                           [-1,-2,-1]]),\n",
    "     'emboss' :np.array([[-2,-1,0],\n",
    "                        [-1,1,1],\n",
    "                        [0,1,2]]),\n",
    "     'blur' :np.array([[0.0625,0.125,0.0625],\n",
    "                      [0.125,0.25,0.125],\n",
    "                      [0.0625,0.125,0.0625]])\n",
    "     \n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ydirect = convolve2d(h['left_sobel'],x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize =  (8,4) )\n",
    "plt.imshow(ydirect);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to accelerate calculation, the properties of the Fast Fourier Transform, and convolution are applied. Within the $Scipy.Signal$ library, the \"$fftconvolve$\" command will be used in lieu of the standard convolution. Observe that both operations produce the same image after applying the filter, but the convolution involving the Fast Fourier Transform is markedly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time yfft = fftconvolve(h['left_sobel'],x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize =  (8,4) )\n",
    "plt.imshow(yfft);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(ydirect, yfft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the image has changed after applying the filter. this is because the filter is a $3x3$matrix, and as such produces some \"excess\" pixels when it is applied to the edges of the image. This be alleviated by using the Fast Fourier Transform to create an image composed of four copies of the original image and slicing the original image out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time yfft = fftconvolve(h['bottom_sobel'],x, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize =  (8,4) )\n",
    "plt.imshow(yfft);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft2(x)[:5,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft2(x)[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrev = x[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize =  (8,4) )\n",
    "plt.imshow(xrev);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xext_x = np.hstack([x,xrev])\n",
    "plt.figure( figsize =  (16,4) )\n",
    "plt.imshow(xext_x);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sym = np.vstack([xext_x, xext_x[::-1,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize =  (8,8) )\n",
    "plt.imshow(x_sym);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft2(x_sym )[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dctn(x)[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yedges = fftconvolve(h['EdgeDetector'], x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(yedges)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Using Edge Filter')\n",
    "axes[1].imshow(x)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Original Image');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the images are passed through a filter, is it possible to reconstruct the original from the filtered result? In order to come to a conclusion on this matter, we apply the two-dimensional Fast Fourier Transform to the convolution operator, and convolve it with the filtered image. Then, the inverse two-dimensional Fast Fourier Transform is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = fft2(h['EdgeDetector'])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hinv = 1/H \n",
    "Hinv[0,0] = 0\n",
    "Hinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinv = ifft2( Hinv )\n",
    "hinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec = fftconvolve( hinv, yedges)\n",
    "x_rec[:5, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(x_rec.real )\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Reconstructed from Edge Detected')\n",
    "axes[1].imshow(x)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title(\"Original Image -- Yeah, Inversion Doesn't Work!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we note that this inversion technique is not effective in reverting the filtered image back to the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = x.shape\n",
    "yedges = fftconvolve(h['Laplacian'], x )/(M-1)/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(yedges)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Using Laplacian Edge Filter (2nd derivative)')\n",
    "axes[1].imshow(x)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Original Image');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution image filters are not limited in dimension to $3x3$ matrix operators. To illustrate, we define several $5x5$ convolution operators and compare and contrast between the two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five = {     \n",
    "       'left_sobel':np.array([[ 1,  2,  0,  -2, -1],\n",
    "                 [ 4, 8, 0, -8, -4],\n",
    "                 [ 6, 12, 0, -12,-6],\n",
    "                 [ 4, 8, 0, -8, -4],\n",
    "                 [ 1,  2,  0,  -2, -1] ]),\n",
    "      'bottom_sobel':np.array([[ -1,  -4,  -6,  -4, -1],\n",
    "                 [ -2, -8, -12, -8, -2],\n",
    "                 [ 0, 0, 0, 0,0],\n",
    "                 [ 2, 8, 12, 8, 2],\n",
    "                   [ 1,  4,  6,  4, 1]]),\n",
    "       'right_sobel':np.array([[ -1,  -2,  0,  2, 1],\n",
    "                 [ -4, -8, 0, 8, 4],\n",
    "                 [ -6, -12, 0, 12,6],\n",
    "                 [ -4, -8, 0, 8, 4],\n",
    "                 [ -1,  -2,  0,  2, 1] ]), \n",
    "       'top_sobel':np.array([[ 1,  4,  6,  4, 1],\n",
    "                 [ 2, 8, 12, 8, 2],\n",
    "                 [ 0, 0, 0, 0,0],\n",
    "                 [ -2, -8, -12, -8, -2],\n",
    "                 [ -1,  -4,  -6,  -4, -1] ]),\n",
    "    'Blur':np.array([[ 1,  4,  6,  4, 1],\n",
    "                 [ 4, 16, 24, 16, 4],\n",
    "                 [ 6, 24, 36, 24, 6],\n",
    "                 [ 4, 16, 24, 16, 4],\n",
    "                 [ 1,  4,  6,  4, 1]]) / 256\n",
    "     \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yedges = fftconvolve(five['Blur'], x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(yedges)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Gaussian Blurred')\n",
    "axes[1].imshow(x)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Original Image');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt=fftconvolve(five['bottom_sobel'],x, )\n",
    "botthree=fftconvolve(h['bottom_sobel'],x, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(filt)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Bottom Sobel(5x5)')\n",
    "axes[1].imshow(botthree)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Bottom Sobel(3x3)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt=fftconvolve(five['top_sobel'],x, )\n",
    "topthree=fftconvolve(h['top_sobel'],x, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(filt)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Top Sobel (5x5)')\n",
    "axes[1].imshow(topthree)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Top Sobel (3x3)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, we note that the $5x5$ operator produces an image that is marginally more blurred than the $3x3$ operator. To verify this behavior, we import a separate image with larger dimensions (i.e. the ETSU Minidome image) and compare the results further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = plt.imread('ETSUminidomeFront.jpg')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = color.rgb2gray(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (8,4) )  #15.5,6))\n",
    "plt.gray() # plot image in grayscale\n",
    "plt.imshow(y);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini=fftconvolve(five['top_sobel'],y, )\n",
    "mini3=fftconvolve(h['top_sobel'],y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(mini)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Top Sobel (5x5)')\n",
    "axes[1].imshow(mini3)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Top Sobel (3x3)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe here that the larger image filter produced an image that is lighter, and that the text is easier to distinguish and more legible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini=fftconvolve(five['bottom_sobel'],y, )\n",
    "mini3=fftconvolve(h['bottom_sobel'],y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(mini)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Bottom Sobel (5x5)')\n",
    "axes[1].imshow(mini3)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Bottom Sobel (3x3)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini=fftconvolve(five['right_sobel'],y, )\n",
    "mini3=fftconvolve(h['right_sobel'],y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( nrows = 2, ncols = 1, figsize =  (8,8) )\n",
    "axes[0].imshow(mini)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Right Sobel (5x5)')\n",
    "axes[1].imshow(mini3)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Right Sobel (3x3)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the larger convolution produces more definition after filtering for the above operators, it can be surmised that smaller operators are better for smaller images, while larger images require larger filter matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
